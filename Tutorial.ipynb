{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiprocessing in Python: getting around the GIL\n",
    "\n",
    "## What is the GIL?\n",
    "\n",
    "https://wiki.python.org/moin/GlobalInterpreterLock\n",
    "\n",
    "> In CPython, the global interpreter lock, or GIL, is a mutex that prevents multiple native threads from executing Python bytecodes at once. This lock is necessary mainly because CPython's memory management is not thread-safe. (However, since the GIL exists, other features have grown to depend on the guarantees that it enforces.)\n",
    "\n",
    "In practice, it means that multithreaded python code doesn't *actually* use multiple CPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MP Basics\n",
    "\n",
    "Deserializing JSON is slow, but JSON is such a convenient storage format. I've been logging requests to a file (1M requests) with one JSON blob per line, and I want to some basic analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import json\n",
    "\n",
    "def get_ip(line):\n",
    "    item = json.loads(line)\n",
    "    return item['IP']\n",
    "\n",
    "counter = collections.Counter()\n",
    "with open('requests.log') as handle:\n",
    "    %time ips = list(map(get_ip, handle.readlines()))\n",
    "    counter.update(ips)\n",
    "\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "counter = collections.Counter()\n",
    "with open('requests.log') as handle:\n",
    "    with Pool(4) as mp:\n",
    "        %time ips = list(mp.map(get_ip, handle.readlines()))\n",
    "        counter.update(ips)\n",
    "\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something more fun\n",
    "\n",
    "Counting IP addresses in half the time is useful, but not a lot of fun. There's also so much time wasted creating and destroying processes, that you don't really see a significant boost from running them in parallel.\n",
    "\n",
    "I wanted a more fun example, but also something that makes better use of offloading computation to multiple processors. So I thought, image processing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core import display\n",
    "from PIL import Image\n",
    "\n",
    "import filters\n",
    "\n",
    "with Image.open('./clementine.jpg') as img:\n",
    "    %time img = filters.ascii(img)\n",
    "    img.save('./ascii_clementine.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`filters` is a library that I wrote myself that just converts a regular image into an ascii version of the same. In the above example, I'm converting [my girlfriend's cat](/files/clementine.jpg) into an [ascii version](/files/ascii_clementine.jpg) of the same.\n",
    "\n",
    "How do we offload this to multiple processors? Animated GIFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gif_frames import read_frames, write_frames\n",
    "\n",
    "def convert(frames):\n",
    "    for frame in frames:\n",
    "        yield filters.ascii(frame)\n",
    "\n",
    "with Image.open('./kitten.gif') as img:\n",
    "    %time ascii_frames = list(convert(read_frames(img)))\n",
    "\n",
    "with open('./ascii_kitten.gif', 'wb') as handle:\n",
    "    write_frames(handle, ascii_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[kitten.gif](/files/kitten.gif) -> [ascii_kitten.gif](/files/ascii_kitten.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Manager, Process, JoinableQueue\n",
    "import queue\n",
    "\n",
    "def runner(q, l):\n",
    "    while True:\n",
    "        try:\n",
    "            frame = q.get_nowait()\n",
    "            l.append(filters.ascii(frame))\n",
    "            q.task_done()\n",
    "        except queue.Empty:\n",
    "            break\n",
    "    \n",
    "def convert_mp(frames):\n",
    "    with Manager() as manager:\n",
    "        q = JoinableQueue()\n",
    "        l = manager.list()\n",
    "        \n",
    "        for frame in frames:\n",
    "            q.put(frame)\n",
    "\n",
    "        pool = [Process(target=runner, args=(q, l))\n",
    "                for x in range(4)]\n",
    "        for p in pool:\n",
    "            p.start()\n",
    "            \n",
    "        q.join()\n",
    "\n",
    "        return list(l)\n",
    "\n",
    "with Image.open('./kitten.gif') as img:\n",
    "    %time ascii_frames = convert_mp(read_frames(img))\n",
    "\n",
    "with open('./ascii_kitten2.gif', 'wb') as handle:\n",
    "    write_frames(handle, ascii_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[kitten.gif](/files/kitten.gif) -> [ascii_kitten2.gif](/files/ascii_kitten2.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, you will need to be running\n",
    "#   redis-server\n",
    "# And:\n",
    "#   celery -A celery_tasks worker\n",
    "import celery_tasks\n",
    "\n",
    "with Image.open('./kitten.gif') as img:\n",
    "     %time ascii_frames = celery_tasks.ascii_filter.map(read_frames(img)).apply_async().get()\n",
    "        \n",
    "with open('./ascii_kitten3.gif', 'wb') as handle:\n",
    "    write_frames(handle, ascii_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[kitten.gif](/files/kitten.gif) -> [ascii_kitten3.gif](/files/ascii_kitten3.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with Image.open('./kitten.gif') as img:\n",
    "    with Pool(4) as mp:\n",
    "        %time ascii_frames = mp.map(filters.ascii, read_frames(img))\n",
    "\n",
    "with open('./ascii_kitten4.gif', 'wb') as handle:\n",
    "    write_frames(handle, ascii_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[kitten.gif](/files/kitten.gif) -> [ascii_kitten4.gif](/files/ascii_kitten4.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared state\n",
    "\n",
    "You can't share state with variables defined outside of your map function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foo = []\n",
    "\n",
    "def add_to_foo(i):\n",
    "    foo.append(i)\n",
    "    \n",
    "list(map(add_to_foo, range(0, 10)))\n",
    "print(foo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bar = []\n",
    "\n",
    "def add_to_bar(i):\n",
    "    bar.append(i)\n",
    "\n",
    "with Pool(4) as mp:\n",
    "    list(mp.map(add_to_bar, range(0, 10)))\n",
    "print(bar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
